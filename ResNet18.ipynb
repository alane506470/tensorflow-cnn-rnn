{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices=tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(\n",
    "    '/physical_device:GPU:0', True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寫一個捷徑\n",
    "#繼承tensorflow.python.keras.layers\n",
    "class ResBlock(layers.Layer):\n",
    "    #初始化類別\n",
    "    def __init__(self,filter_nums,strides=1,residual_path=False):\n",
    "        super(ResBlock,self).__init__()\n",
    "        self.conv_1 = layers.Conv2D(filter_nums,(3,3),strides=strides,padding='same')\n",
    "        self.bn_1 = layers.BatchNormalization()\n",
    "        self.act_relu= layers.Activation('relu')\n",
    "        \n",
    "        self.conv_2 = layers.Conv2D(filter_nums,(3,3),strides=1,padding='same')\n",
    "        self.bn_2 = layers.BatchNormalization()\n",
    "        \n",
    "        if strides !=1:\n",
    "            self.block=Sequential()\n",
    "            self.block.add(layers.Conv2D(filter_nums,(1,1),strides=strides))\n",
    "        else:\n",
    "            self.block = lambda x:x\n",
    "    #實做call function，提供給model執行        \n",
    "    def call(self,inputs,training=None):\n",
    "        x=self.conv_1(inputs)\n",
    "        x=self.bn_1(x,training=training)\n",
    "        x=self.act_relu(x)\n",
    "        x=self.conv_2(x)\n",
    "        x=self.bn_2(x,training=training)\n",
    "        \n",
    "        identity= self.block(inputs)\n",
    "        outputs = layers.add([x,identity])\n",
    "        outputs= tf.nn.relu(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):\n",
    "    def __init__(self,layers_dims,nums_class=10):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        self.model = Sequential([layers.Conv2D(64,(3,3),strides=(1,1)),\n",
    "                             layers.BatchNormalization(),\n",
    "                             layers.Activation('relu'),\n",
    "                             layers.MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')])\n",
    "\n",
    "        self.layer_1 = self.ResNet_build(64,layers_dims[0])\n",
    "        self.layer_2 = self.ResNet_build(128,layers_dims[1],strides=2)   \n",
    "        self.layer_3 = self.ResNet_build(256,layers_dims[2],strides=2) \n",
    "        self.layer_4 = self.ResNet_build(512,layers_dims[3],strides=2)   \n",
    "        self.avg_pool = layers.GlobalAveragePooling2D()                 \n",
    "        self.fc_model = layers.Dense(nums_class)    \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.model(inputs)\n",
    "        x = self.layer_1(x)        \n",
    "        x = self.layer_2(x) \n",
    "        x = self.layer_3(x)                               \n",
    "        x = self.layer_4(x) \n",
    "        x = self.avg_pool(x) \n",
    "        x = self.fc_model(x)\n",
    "        return x\n",
    "\n",
    "    def ResNet_build(self,filter_nums,block_nums,strides=1):\n",
    "        build_model = Sequential()\n",
    "        build_model.add(ResBlock(filter_nums,strides))\n",
    "        for _ in range(1,block_nums):\n",
    "            build_model.add(ResBlock(filter_nums,strides=1))\n",
    "        return build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet([2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(x_test,y_test)= keras.datasets.cifar10.load_data()\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(x,y):\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.\n",
    "    y=tf.cast(y,dtype=tf.int32)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RestNet_model = ResNet18()\n",
    "RestNet_model.build(input_shape=(None,32,32,3))\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "data=data.map(feature_scale).shuffle(10000).batch(512)\n",
    "\n",
    "data_test=tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "data_test = data_test.map(feature_scale).batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data)\n",
    "samples= next(data_iter)\n",
    "print(samples[0].shape,samples[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    for step,(x,y) in enumerate(data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits=RestNet_model(x)\n",
    "                y_one_hot = tf.one_hot(y,depth=10)\n",
    "                loss = tf.losses.categorical_crossentropy(y_one_hot,logits,from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "            grad=tape.gradient(loss,RestNet_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grad,RestNet_model.trainable_variables))\n",
    "            print(step)\n",
    "            if step %50==0:\n",
    "                print(i,step,'loss:',float(loss))\n",
    "            total_loss = 0\n",
    "            total_num=0\n",
    "    for x,y in data_test:\n",
    "\n",
    "        logits = RestNet_model(x)\n",
    "    \n",
    "        prob = tf.nn.softmax(logits,axis=1)\n",
    "        pred = tf.argmax(prob,axis=1)\n",
    "\n",
    "        pred = tf.cast(pred,dtype=tf.int32)\n",
    "        correct = tf.equal(pred,y)\n",
    "\n",
    "        result = tf.reduce_sum(tf.cast(correct,dtype=tf.int32))\n",
    "\n",
    "        total_loss += int(result)\n",
    "        total_num += x.shape[0]\n",
    "\n",
    "    acc = total_loss/total_num\n",
    "    print(i,'acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
